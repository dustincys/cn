---
layout: post
category: technology
title: Nyxt下一代浏览器？
matheq: no
comments: yes
tags: [nyxt, 浏览器]
share: yes
toc: no
---

下一代浏览器必将具备高度个性化、智能化及强大的信息处理能力这些显著特征。
它不可避免地需要具备以下几个核心功能：

1. 能够通过记录操作生成用于上传或爬取数据的代码和插件。
2. 具备数据清洗及分析的能力，并可以实现数据的可视化。

为了便于理解，我们可以把这两项功能进一步展开：
首先，在进行大规模数据研究时，研究者需要从大量的信息中筛选出有效数据。下一代的浏
览器应通过记录用户操作，自动生成相应的数据抓取或上传代码，极大地提高了用户在数据
获取方面的效率。
其次，数据的清洗与分析是数据科学研究的关键环节，只有通过准确的数据清洗和分析，才
能确保得出的研究结果的可靠性。新一代浏览器将集成数据清洗，数据分析到一体，简化研
究人员的操作流程。
最后，数据的可视化将使得复杂的数据更易于理解和解读，新一代浏览器也将此作为必备的
功能。

号称“黑客的浏览器”的[Nyxt](https://nyxt.atlas.engineer/)有一点下一代浏览器的影
子。其优势如下：

- 由标准lisp开发，可通过slime或sly直接与emacs交互。

这相当于赋予浏览器一个“操作系统”。可以写代码、抓数据、做分析等等。
举几个例子：

  1. 可以无缝对接org-roam进行快速更加智能地信息抓取。例如，将一个网页先抓取之后，
  然后在后台调用GPT4进行总结，然后`capture`到`org-roam`中。

  2. 可以实现正反双向辅助。例如，当用户想要在浏览器中正在浏览的网页，EMACS端自动
     将`org-roam`相关的节点生成的网络图显示到当前网页一脚。或者当EMACS端正在开发
     网页，可以无缝同步跳转到浏览器对应的位置。

  3. 可实现录制宏的操作，每一段录制会将命令整合成新命令绑定用户定义的快捷键上，
     录制的宏包括命令间隔时间。基于`common lisp`的强大威力，甚至可以使浏览器具备操作
     系统上任何程序的能力。这样的宏就可以实现“硬解码”式爬虫，即数据的抓取不需
     要用户写代码，而是直接与浏览器交互。当然如果需要，也很容易将录制的宏解析成
     主流爬虫框架的代码。

- 具有REPL的浏览器。

[所有具有REPL程序的生命力都极其顽强](https://dustincys.github.io/cn/2023/03/org-roam/)。

